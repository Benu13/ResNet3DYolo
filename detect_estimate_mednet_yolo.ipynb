{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll create model for level boundary estimation:  \n",
    "- estimating level instances for series  \n",
    "- estimating level box - once we find best performing boxes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "import timm\n",
    "from typing import List, Union, Dict\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from detection_train.Box_model_mednet import BoxModel, Nms3dAxial, Nms3dSagittalForamina, Nms3d\n",
    "\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "postprocessing found bboxes:\n",
    "Include guaranteed information about bboxes in image. \n",
    "-> 5 classes each with one bbox or 1 class with 5 bbox\n",
    "-> If there exist level n-1 and n+1 in image there must also exist level n\n",
    "-> The boxes of levels n-1, n, n+1 must be aligned next to another in heigh dimention\n",
    "-> The boxes must overlap in x dimention to some extend \n",
    "-> If there exist series of boxes for levels n, n+1, n+2 and image height is bigger than mean level heigh than the n+3 level must also exist - same situation in reverse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, data_info:Dict[str, pd.DataFrame], config:Dict):\n",
    "        # data_info: dict consisting of series types and dataframe with their info\n",
    "        # config: dict - dataset configuration\n",
    "\n",
    "        self.used_series_types = config['load_series']\n",
    "        self.study_ids = np.unique(np.concatenate([series.study_id.unique() for series in data_info.values() if series is not None]))\n",
    "        self.data_info = data_info\n",
    "        self.return_series_type = config['return_series_type']\n",
    "\n",
    "        self._condition_list = ['Left Neural Foraminal Narrowing', \n",
    "                                'Left Subarticular Stenosis', \n",
    "                                'Right Neural Foraminal Narrowing', \n",
    "                                'Right Subarticular Stenosis', \n",
    "                                'Spinal Canal Stenosis']\n",
    "        \n",
    "        self._status_map = {'Normal/Mild': [1., 0., 0.],\n",
    "                            'Moderate': [0., 1., 0.],\n",
    "                            'Severe': [0., 0., 1.]}\n",
    "        \n",
    "        self.level_ind = {'L1/L2': 0, 'L2/L3': 1, 'L3/L4': 2, 'L4/L5': 3, 'L5/S1':4}\n",
    "\n",
    "        self.dataset_path = config['dataset_path']\n",
    "        self.image_type = config['image_type']\n",
    "        self.data = []\n",
    "        self.prepare_data()\n",
    "\n",
    "    def get_condition_labels(self, series_info:pd.DataFrame):\n",
    "        labels = []\n",
    "        cond_presence_masks = []\n",
    "        level_presence_mask = []\n",
    "        for level, _ in self.level_ind.items():\n",
    "            if not series_info[series_info['level']==level].empty:\n",
    "                labels.append(series_info[series_info['level']==level].iloc[0].status)\n",
    "                cond_presence_masks.append(series_info[series_info['level']==level].iloc[0].presence_mask)\n",
    "                level_presence_mask.append(True)\n",
    "            else:\n",
    "                level_presence_mask.append(False)\n",
    "\n",
    "        return np.array(labels), np.array(cond_presence_masks), np.array(level_presence_mask)\n",
    "\n",
    "    def info2dict(self, series_info, stype=None): #remember axials can be combination of different serieses (sagittals can't)\n",
    "        level0 = series_info.iloc[0]\n",
    "        data_dict = {}\n",
    "        labels, masks, level_presence= self.get_condition_labels(series_info)\n",
    "\n",
    "        data_dict['study_id'] = level0.study_id\n",
    "        data_dict['series_id'] = level0.series_id\n",
    "        data_dict['width'] = level0.image_width\n",
    "        data_dict['height'] = level0.image_height\n",
    "        data_dict['reversed'] = level0.reversed\n",
    "        data_dict['series_type'] = stype\n",
    "        data_dict['files'] = [f\"{self.dataset_path}/{data_dict['study_id']}/{data_dict['series_id']}/{instance}.{self.image_type}\" for instance in level0.present_instances]\n",
    "        data_dict['labels'] = labels\n",
    "        data_dict['masks'] = masks\n",
    "        data_dict['level_presence'] = np.where(level_presence==True)[0]\n",
    "        data_dict['IPP'] = level0.IPP\n",
    "        return data_dict\n",
    "   \n",
    "    def prepare_data(self):\n",
    "        # prepare paths for every image to load\n",
    "        \n",
    "        with tqdm(total=len(self.study_ids), desc=\"Preparing data: \") as pbar:\n",
    "            for study_id in self.study_ids:\n",
    "                study_dict = dict(\n",
    "                                sagittal=[], \n",
    "                                sagittal_t2=[], \n",
    "                                axial=[])\n",
    "                present = 0\n",
    "                for stype in self.used_series_types:\n",
    "                    for series_id in self.data_info[stype].query(f'study_id == {study_id}').series_id.unique():\n",
    "                        present += 1\n",
    "                        ddict = self.info2dict(self.data_info[stype][self.data_info[stype].series_id==series_id], stype=stype)\n",
    "                        study_dict[stype].append(ddict)\n",
    "                \n",
    "                if present == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    self.data.append(study_dict)\n",
    "                pbar.update(1)\n",
    "         \n",
    "    def load_series(self, data) -> np.ndarray:\n",
    "        oimg = np.zeros((len(data['files']), data['height'], data['width']), dtype = np.uint8)\n",
    "        for i, path in enumerate(data['files']):  \n",
    "            try:      \n",
    "                oimg[i,:,:] = np.array(Image.open(path), dtype = np.uint8)\n",
    "            except ValueError:\n",
    "                temp = np.array(Image.open(path), dtype = np.uint8) \n",
    "                oimg[i,:temp.shape[0],:temp.shape[1]] = temp\n",
    "                del temp\n",
    "    \n",
    "        if data['series_type'] == 'sagittal':\n",
    "            key = np.argsort([d[0] for d in data['IPP']])[::-1]\n",
    "            oimg = oimg[key]\n",
    "    \n",
    "        return oimg.copy()\n",
    "\n",
    "    def prepare_series(self, data):\n",
    "        # img [5, d, h, w]\n",
    "        level_labels = torch.tensor(data['box_labels'], dtype=torch.int64)\n",
    "        cond_labels = torch.zeros((5,5,3), dtype=torch.int64)\n",
    "        cond_masks = torch.zeros((5,5), dtype=torch.int64)\n",
    "        cond_labels[level_labels,...] = torch.tensor(data['labels'], dtype=torch.int64)\n",
    "        cond_masks[level_labels,...] = torch.tensor(data['label_presence_mask'], dtype=torch.int64)\n",
    "\n",
    "        return cond_labels, cond_masks\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        return None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return(len(self.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxDatasetUnited(Dataset):\n",
    "    def __init__(self, data_info:Dict[str, pd.DataFrame], config:Dict):\n",
    "        super(BoxDatasetUnited, self).__init__(data_info, config)\n",
    "        #split data to individual serieses from dict of study-series_type pairs\n",
    "       \n",
    "    def flip_sides(self, volume, labels, masks):\n",
    "        # flip left/right sides and their labels\n",
    "        volume = volume.flip(2)\n",
    "        labels = labels[:, [2,3,0,1,4]]\n",
    "        masks = masks[:, [2,3,0,1,4]]\n",
    "        return volume, labels, masks\n",
    "\n",
    "    def __getitem__(self, index: int)->tuple[np.ndarray, np.ndarray]:\n",
    "        adata = self.data[index]\n",
    "\n",
    "        type_to_ind = {}\n",
    "        ind = 0\n",
    "        for st in self.used_series_types:\n",
    "            type_to_ind[st] = ind\n",
    "            ind+=1\n",
    "\n",
    "        oimgs = {\n",
    "            'study_id': 0,\n",
    "            'sagittal': [],\n",
    "            'sagittal_t2': [],\n",
    "            'axial': []\n",
    "        }\n",
    "        cond_labels = torch.zeros(5,5,3)\n",
    "        cond_masks = torch.zeros(5,5)\n",
    "        for key, data_list in adata.items():\n",
    "            if data_list:\n",
    "                for data in data_list: #schuffle if you want random in some cases\n",
    "                   # print(data['study_id'])\n",
    "                    oimgs['study_id'] = data['study_id']\n",
    "                    try:\n",
    "                        oimg = self.load_series(data)\n",
    "                    except ZeroDivisionError: # one series was skipped in data preparation and now it raises exception ;_;\n",
    "                            continue\n",
    "  \n",
    "                    oimgs[key].append(torch.tensor(oimg, dtype=torch.float))\n",
    "                    cond_labels[data['level_presence']] += torch.tensor(data['labels'])\n",
    "                    cond_masks[data['level_presence']] += torch.tensor(data['masks'])\n",
    "        \n",
    "        cond_labels = cond_labels.to(dtype=torch.int64).argmax(-1)\n",
    "        cond_masks = cond_masks.clamp(min=0, max =1).to(dtype=torch.int64)\n",
    "        \n",
    "        return oimgs, cond_labels, cond_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    \n",
    "    def get_random_by_stype(self):\n",
    "        return self[random.randint(0, len(self)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_config ={\n",
    "    'dataset_path': \"/workspaces/RSNA_LSDC/inputs/dataset_vl\",\n",
    "    'load_series': ['sagittal', 'sagittal_t2', 'axial'], # series types to load into dataset ['sagittal', 'axial', 'sagittal_t2']\n",
    "   \n",
    "    'return_series_type': False, # If True getitem will also return series orignial type\n",
    "    'image_type': 'png',\n",
    "}\n",
    "\n",
    "tsd = pd.read_csv(f'/workspaces/RSNA_LSDC/inputs/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv').iloc[0:100]\n",
    "#tsd = tsd[tsd['study_id'] == 4003253]\n",
    "\n",
    "data_sagittal = pd.read_pickle(\"/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_unified_sagital_t1.pkl\")\n",
    "data_sagittal_t2 = pd.read_pickle(\"/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_unified_sagital_t2.pkl\")\n",
    "data_axial = pd.read_pickle('/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_axial_unified.pkl')\n",
    "train_ids = tsd.study_id.unique()\n",
    "\n",
    "train_data={'sagittal': data_sagittal[data_sagittal.study_id.isin(train_ids)],\n",
    "            'sagittal_t2': data_sagittal_t2[data_sagittal_t2.study_id.isin(train_ids)],\n",
    "            'axial': data_axial[data_axial.study_id.isin(train_ids)]}\n",
    "\n",
    "bb = BoxDatasetUnited(train_data, train_dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.read_csv(\"/workspaces/RSNA_LSDC/inputs/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = dict([(0,'r'),(1,'g'), (2,'b'), (3,'m'), (4, 'y')])\n",
    "oimgs, labels, masks = bb[7]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SagittalTrainer():\n",
    "    def __init__(self, model, config, train_data, eval_data) -> None:\n",
    "\n",
    "        self.print_evaluation = config[\"print_evaluation\"] if \"print_evaluation\" in config else False\n",
    "        self.steps_per_plot = config[\"steps_per_plot\"]\n",
    "\n",
    "        self.checkpoints = config['checkpoints']\n",
    "        self.save_path = config['save_path']\n",
    "        self.step_per_save = config['step_per_save']\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"Device set to {self.device}\")\n",
    "\n",
    "        self.model_name = config['model_name']\n",
    "        self.model = model().to(self.device)\n",
    "        #self.model.to(self.device)\n",
    "        \n",
    "        self.optimizer = config[\"optimizer\"](self.model.parameters(),**config[\"optimizer_params\"])\n",
    "\n",
    "        self.dataloaders = {'train': torch.utils.data.DataLoader(BoxDatasetUnited(train_data, config['train_dataset_config']), batch_size=config[\"batch_size\"], shuffle=True, num_workers=12, prefetch_factor=1),\n",
    "                           'val': torch.utils.data.DataLoader(BoxDatasetUnited(eval_data, config['val_dataset_config']), batch_size=config[\"batch_size\"], shuffle=False, num_workers=12, prefetch_factor=1)}\n",
    "        \n",
    "        self.max_epochs = config[\"epochs\"]\n",
    "        self.early_stopping = config['early_stopping']\n",
    "        self.early_stopping_tresh = config['early_stopping_treshold']\n",
    "\n",
    "        # scheduler\n",
    "        if config[\"scheduler\"]:\n",
    "            if 'epochs' in list(config['scheduler_params'].keys()):\n",
    "                config['scheduler_params']['epochs'] = self.max_epochs\n",
    "            if 'steps_per_epoch' in list(config['scheduler_params'].keys()):\n",
    "                config['scheduler_params']['steps_per_epoch'] = len(self.dataloaders['train'])\n",
    "            self.scheduler = config[\"scheduler\"](self.optimizer,**config[\"scheduler_params\"])\n",
    "            self.one_cycle_sched = self.scheduler.__class__.__name__ == 'OneCycleLR'\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "        \n",
    "        ## Evaluation metrics\n",
    "        self.best_ll = 0.1\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model.canale_estimator.state_dict(), os.path.join(self.save_path, f\"{self.model_name}_best.pt\"))\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.max_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{self.max_epochs}\")\n",
    "            self.train_one_epoch()\n",
    "            self.eval_one_epoch()\n",
    "            #print examples\n",
    "            #checkpoint\n",
    "            if epoch%5==0:\n",
    "                pass\n",
    "\n",
    "    def train_one_epoch(self):\n",
    "\n",
    "        self.model.train()  # Set model to training mode\n",
    "        metrics = defaultdict(list)\n",
    "        \n",
    "        with tqdm(self.dataloaders['train'], unit = \"batch\",\n",
    "                    total = len(self.dataloaders['train'])) as tepoch:\n",
    "            for oimgs, labels, masks in self.dataloaders['train']:\n",
    "\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    labels = labels.reshape(5,-1)\n",
    "                    masks = masks.reshape(5,-1)\n",
    "                    loss, loss_info_canale, loss_info_sub, loss_info_foramina = self.model.get_loss(oimgs, \n",
    "                                                          labels[:,4].unsqueeze(-1).to('cuda'), labels[:,[1,3]].to('cuda').reshape(-1,1), labels[:,[0,2]].to('cuda').reshape(-1,1), \n",
    "                                                          masks[:,4].to('cuda'), masks[:,[1,3]].to('cuda').reshape(-1), masks[:,[0,2]].to('cuda').reshape(-1))\n",
    "                    for loss_t, loss_v in loss_info_sub.items():\n",
    "                        metrics[loss_t+'_subart'].append(loss_v.clone().detach().cpu().numpy())\n",
    "                    for loss_t, loss_v in loss_info_canale.items():\n",
    "                        metrics[loss_t+'_canale'].append(loss_v.clone().detach().cpu().numpy())\n",
    "                    for loss_t, loss_v in loss_info_foramina.items():\n",
    "                        metrics[loss_t+'_foramina'].append(loss_v.clone().detach().cpu().numpy())\n",
    "                    self.optimizer.zero_grad()\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    if self.scheduler and self.one_cycle_sched:\n",
    "                        self.scheduler.step()\n",
    "\n",
    "                #update tqdm data\n",
    "                tepoch.set_description(self.metrics_description(metrics, 'train'))\n",
    "                tepoch.update(1)\n",
    "\n",
    "        if self.scheduler and not self.one_cycle_sched:\n",
    "            self.scheduler.step()\n",
    "\n",
    "\n",
    "    def eval_one_epoch(self):\n",
    "        self.model.eval()\n",
    "        alabels = []\n",
    "        apreds = []\n",
    "        aweight = []\n",
    "        metrics_d = defaultdict(list)\n",
    "\n",
    "        with tqdm(self.dataloaders['train'], unit = \"batch\",\n",
    "                    total = len(self.dataloaders['val'])) as tepoch:\n",
    "            for oimgs, labels, masks in self.dataloaders['val']:\n",
    "                #labels = labels[:,:,4].reshape(5,-1)\n",
    "                #masks = masks[:,:,4].reshape(5,-1)\n",
    "                #masks[:, [0,2,1,3]] = 0\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    s = self.model.predict(oimgs)\n",
    "                    preds = s.get_condition_as_tensor()\n",
    "                    apreds.append(preds.reshape(-1, 3))\n",
    "\n",
    "                labels=  labels.reshape(-1)\n",
    "                weights = 2**labels\n",
    "                weights[torch.logical_not(masks.reshape(-1))] = 0.\n",
    "                alabels.append(labels)\n",
    "                aweight.append(weights)\n",
    "\n",
    "\n",
    "                #update tqdm data\n",
    "                tepoch.update(1)\n",
    "        alabels = torch.cat(alabels, dim=0).cpu().numpy()\n",
    "        apreds = torch.cat(apreds, dim=0).cpu().numpy()\n",
    "        aweight=torch.cat(aweight, dim=0).cpu().numpy()\n",
    "\n",
    "        #prind confusion matrix for every condition\n",
    "        conditions = ['Left Neural Foraminal Narrowing', \n",
    "                                'Left Subarticular Stenosis', \n",
    "                                'Right Neural Foraminal Narrowing', \n",
    "                                'Right Subarticular Stenosis', \n",
    "                                'Spinal Canal Stenosis']\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=len(conditions), figsize=(15,5))\n",
    "        if len(conditions) > 1:\n",
    "            ax = ax.ravel()\n",
    "        else:\n",
    "            ax = [ax]\n",
    "        for i in range(len(conditions)):\n",
    "            cl = alabels[i::len(conditions)]\n",
    "            cpred = apreds[i::len(conditions),:].argmax(-1)\n",
    "            cm = confusion_matrix(cl, cpred)\n",
    "            ax[i].set_title(conditions[i])\n",
    "            ConfusionMatrixDisplay(\n",
    "                confusion_matrix=cm).plot(ax=ax[i], colorbar=False)\n",
    "        plt.show()\n",
    "\n",
    "        ll = log_loss(alabels, apreds, normalize=True, sample_weight=aweight)\n",
    "        if ll < self.best_ll:\n",
    "            self.save_model()\n",
    "            self.best_ll = ll\n",
    "\n",
    "        print(\"Score:\", ll)\n",
    "        \n",
    "        \n",
    "    def metrics_description(self, metrics:dict, phase:str)->str:\n",
    "        outputs = phase + \": ||\"\n",
    "        for k in metrics.keys():\n",
    "            outputs += (\" {}: {:4f} ||\".format(k, np.mean(metrics[k])))\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpHead(nn.Module):\n",
    "    \"\"\" MLP classification head\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_classes=1000, mlp_ratio=4, act_layer=nn.ReLU,\n",
    "        norm_layer=nn.LayerNorm, head_dropout=0., bias=True):\n",
    "        super().__init__()\n",
    "        hidden_features = int(mlp_ratio * dim)\n",
    "        self.fc1 = nn.Linear(dim, hidden_features, bias=bias)\n",
    "        self.act = act_layer()\n",
    "        self.norm = norm_layer(hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, num_classes, bias=bias)\n",
    "        self.head_dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.head_dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassModelTimm2d(nn.Module):\n",
    "    def __init__(self, backbone_name, series_dim, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "                                    backbone_name,\n",
    "                                    pretrained=pretrained, \n",
    "                                    features_only=False,\n",
    "                                    in_chans=series_dim[0]*1,\n",
    "                                    num_classes=3,\n",
    "                                    global_pool='avg'\n",
    "                                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, s, d, h, w = x.shape\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        x = x.reshape(b, s*d, h, w)\n",
    "        y = self.model(x)\n",
    "        return y.reshape(b, 3, -1)\n",
    "\n",
    "    def get_loss(self, input, labels, masks):\n",
    "        preds = self.forward(input)\n",
    "        labels = labels\n",
    "        w = 2 ** labels # sample_weight w = (1, 2, 4) for y = 0, 1, 2 (batch_size, n)\n",
    "        w[torch.logical_not(masks)] = 0. # set weight for unnanoted conds to 0\n",
    "        loss = F.cross_entropy(preds, labels, reduction='none', label_smoothing=0.) * w\n",
    "        loss = loss.mean()*torch.tensor(preds.shape[0], dtype=loss.dtype).to(preds.device)\n",
    "\n",
    "        return loss.mean(), dict(cross_entropy=loss.mean().clone().detach())\n",
    "    \n",
    "    def predict(self, input):\n",
    "        return self.forward(input).permute(0,2,1).softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box3d(object):\n",
    "    def __init__(self, x, y, z) -> None:\n",
    "        # 3d box in coordinates of sagittal series\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "    \n",
    "    @classmethod\n",
    "    def bbox_from_view(cls, bbox, view):\n",
    "        if view in ['sagittal', 'sagittal_t2']:\n",
    "            return cls((bbox[0], bbox[3]), (bbox[1], bbox[4]), (bbox[2], bbox[5]))\n",
    "        elif view == 'axial':\n",
    "            return cls((bbox[1], bbox[4]), (bbox[2], bbox[5]), (bbox[0], bbox[3]))\n",
    "        \n",
    "    def get_box_in_view_type(self, view_type):\n",
    "        if view_type in ['sagittal', 'sagittal_t2']:\n",
    "            return self.get_sagittal()\n",
    "        elif view_type == 'coronal':\n",
    "            return self.get_coronal()\n",
    "        elif view_type == 'axial':\n",
    "            return self.get_axial()\n",
    "        \n",
    "    def get_dim_in_view_type(self, view_type):\n",
    "        if view_type in ['sagittal', 'sagittal_t2']:\n",
    "            box = self.get_sagittal()\n",
    "        elif view_type == 'coronal':\n",
    "            box= self.get_coronal()\n",
    "        elif view_type == 'axial':\n",
    "            box= self.get_axial()\n",
    "        return np.array(box[3:]) - np.array(box[0:3])\n",
    "        \n",
    "    def get_sagittal(self):\n",
    "        return [self.x[0], self.y[0], self.z[0], self.x[1], self.y[1], self.z[1]]\n",
    "    def get_coronal(self):\n",
    "        return [self.z[0], self.y[0], self.x[0], self.z[1], self.y[1], self.x[1]]\n",
    "    def get_axial(self):\n",
    "        return [self.z[0], self.x[0], self.y[0], self.z[1], self.x[1], self.y[1]]\n",
    "    \n",
    "    def __add__(self, box):\n",
    "        self.x += box.x[0]\n",
    "        self.y += box.y[0]\n",
    "        self.z += box.z[0]\n",
    "\n",
    "        return self\n",
    "\n",
    "class Condition(object):\n",
    "    def __init__(self, condition_name:str, box: Box3d=None, status=None):\n",
    "        self.condition_name = condition_name\n",
    "        self.box = box\n",
    "        self.status = status\n",
    "        self.status_map = dict([(0,'Normal/Mild'),(1,'Moderate'), (2,'Severe')])\n",
    "        if status is not None:\n",
    "            self.status_name = self.status_map[int(np.argmax(status))]\n",
    "        else:\n",
    "            self.status_name = \"Unknown\"\n",
    "\n",
    "    def get_box_in_view_type(self, view_type):\n",
    "        return self.box.get_box_in_view_type(view_type)\n",
    "    \n",
    "    def set_status(self, status):\n",
    "        self.status = status\n",
    "        if status is not None:\n",
    "            self.status_name = self.status_map[int(np.argmax(status))]\n",
    "\n",
    "class Level(object):\n",
    "    def __init__(self, level_id, bbox: Box3d, score):\n",
    "        self.level_names = dict([(0,'L1/L2'),(1,'L2/L3'), (2,'L3/L4'), (3,'L4/L5'), (4, 'L5/S1')])\n",
    "        self.level_id = level_id\n",
    "        self.level_name = self.level_names[level_id]\n",
    "        self.box = bbox\n",
    "        self.score = score\n",
    "        self.scale = np.concatenate([self.box.get_dim_in_view_type('sagittal')]*2,0)\n",
    "        \n",
    "        self.condition_list = {\n",
    "            'Left Neural Foraminal Narrowing':0,\n",
    "            'Left Subarticular Stenosis':1,\n",
    "            'Right Neural Foraminal Narrowing':2,\n",
    "            'Right Subarticular Stenosis':3,\n",
    "            'Spinal Canal Stenosis':4}\n",
    "        \n",
    "        self.conditions = []\n",
    "        self.status_map = dict([(0,'Normal/Mild'),(1,'Moderate'), (2,'Severe')])\n",
    "        # {'Normal/Mild': 0,\n",
    "        #  'Moderate': 1,\n",
    "        #  'Severe': 2}\n",
    "    \n",
    "    def get_box_in_view_type(self, view_type):\n",
    "        return self.box.get_box_in_view_type(view_type)\n",
    "    \n",
    "    def set_status_to_condition(self, condition_name, status):\n",
    "        for condition in self.conditions:\n",
    "            if condition.condition_name == condition_name:\n",
    "                condition.set_status(status)\n",
    "                break\n",
    "\n",
    "    def add_condition(self, condition, box=None, status=None, boxed_im_size=None, box_view = None):\n",
    "        if box is not None:\n",
    "            box = box/np.array(boxed_im_size*2, dtype = float)[[2,1,0,5,4,3]]\n",
    "            box = Box3d.bbox_from_view(box, box_view).get_box_in_view_type('sagittal') * self.scale\n",
    "            box = Box3d.bbox_from_view(box, 'sagittal')\n",
    "            # convert relative to level box to absolute for scan\n",
    "            box += self.box\n",
    "        self.conditions.append(Condition(condition, box, status=status))\n",
    "\n",
    "    \n",
    "    def add_conditions_from_boxes(self, boxes, map_names, boxed_im_size, box_view):\n",
    "        # map names = dict mapping labels from detector to condition names\n",
    "        # split_lr = split into left/right condition (remember to sort series from left side to right side )\n",
    "        labels = boxes['labels'].detach().cpu().numpy()\n",
    "        boxes = boxes['boxes'].detach().cpu().numpy()\n",
    "\n",
    "        unique_conditions = np.unique(labels)# select unique conditions to split them left/right\n",
    "        for condition in unique_conditions:\n",
    "            cond_ind = np.argwhere(labels==condition).ravel()\n",
    "            if len(cond_ind)==0:\n",
    "                continue\n",
    "            elif len(cond_ind) ==1: # if one we won't check for l/r placement\n",
    "                bb = boxes[cond_ind][0]/np.array(boxed_im_size*2, dtype = float)[[2,1,0,5,4,3]]\n",
    "                ind = 0 if box_view=='axial' else 2\n",
    "                if bb[ind] <0.5:\n",
    "                    side = 'Left '\n",
    "                else:\n",
    "                    side = 'Right '\n",
    "                self.add_condition(side+map_names[condition], box = boxes[cond_ind][0], boxed_im_size=boxed_im_size, box_view=box_view)\n",
    "            else:\n",
    "                # select left/right based on relative placement \n",
    "                ind = 0 if box_view=='axial' else 2\n",
    "                cbox = boxes[cond_ind]\n",
    "                cbox = cbox[cbox[:,ind].argsort()]\n",
    "                # add left\n",
    "                self.add_condition(\"Left \"+map_names[condition], box = cbox[0], boxed_im_size=boxed_im_size, box_view=box_view)\n",
    "                self.add_condition(\"Right \"+map_names[condition], box = cbox[1], boxed_im_size=boxed_im_size, box_view=box_view)\n",
    "            \n",
    "\n",
    "class Series(object):\n",
    "    def __init__(self, volume, series_type, series_id=None):\n",
    "        self.series_id = series_id\n",
    "        self.series_type = series_type\n",
    "        # every series is stored in sagittal view, same is for boxes\n",
    "        self.view = series_type\n",
    "        self.volume = volume\n",
    "        if series_type == 'axial':\n",
    "            # change axial into sagittal for beter generalization\n",
    "            self.volume = self.get_in_view('sagittal')\n",
    "            self.view = 'sagittal'\n",
    "        elif series_type =='sagittal_t2':\n",
    "            self.view = 'sagittal'\n",
    "            \n",
    "        self.scale = np.array(self.volume.shape*2)[[2,1,0, 5, 4, 3]]\n",
    "        self.level_names = dict([(0,'L1/L2'),(1,'L2/L3'), (2,'L3/L4'), (3,'L4/L5'), (4, 'L5/S1')])\n",
    "        self.levels = {\n",
    "            'L1/L2': None,\n",
    "            'L2/L3': None,\n",
    "            'L3/L4': None,\n",
    "            'L4/L5': None,\n",
    "            'L5/S1': None\n",
    "        }\n",
    "        self.color_dict = dict([('L1/L2','r'),('L2/L3','darkorange'), ('L3/L4','gray'), ('L4/L5','m'), ('L5/S1', 'y')])\n",
    "        \n",
    "    def __getitem__(self, level:Union[str, int]):\n",
    "        if isinstance(level, int):\n",
    "            level = self.level_names[level]\n",
    "        return self.levels[level]\n",
    "    \n",
    "    def get_in_view(self,new_view=None):\n",
    "        if not new_view:\n",
    "            new_view = self.view\n",
    "        if self.view in ['sagittal', 'sagittal_t2']:\n",
    "            if new_view in ['sagittal', 'sagittal_t2']:\n",
    "                return self.volume\n",
    "            elif new_view=='coronal':\n",
    "                return self.volume.transpose(2, 1, 0) # n, h, w -> w, h, n\n",
    "            elif new_view=='axial':\n",
    "                return self.volume.transpose(1, 2, 0) #n, h, w -> h, n, w\n",
    "        elif self.view=='axial':\n",
    "            if new_view in ['sagittal', 'sagittal_t2']:\n",
    "                return self.volume.transpose(2, 0, 1) # n, h, w -> w, n, h\n",
    "            elif new_view =='coronal':\n",
    "                return self.volume.transpose(2, 1, 0) # n, h, w -> h, n, w\n",
    "            elif new_view=='axial':\n",
    "                return self.volume\n",
    "    \n",
    "    def get_levels_in_view(self, view, training=False):\n",
    "        level_list = []\n",
    "        level_ind_list = []\n",
    "        volume = self.get_in_view(view)\n",
    "        for l, level in self.levels.items():\n",
    "            level_ind_list.append(l)\n",
    "            if level is not None:\n",
    "                box = np.array(level.get_box_in_view_type(view))\n",
    "                box = box.astype(int)\n",
    "                if training:\n",
    "                    z0, z1 = max(0, box[2]+random.randint(-2,1)),min(volume.shape[0], box[5]+random.randint(-1,2))\n",
    "                    h0, h1 = max(0, box[1]+random.randint(-10,10)),min(volume.shape[1], box[4]+random.randint(-10,10))\n",
    "                    w0, w1 = max(0, box[0]+random.randint(-10,10)),min(volume.shape[2], box[3]+random.randint(-10,10))\n",
    "                    level_list.append(volume[z0: max(z1, z0+1), \n",
    "                                             h0: max(h1, h0+1), \n",
    "                                             w0: max(w1, w0+1)])\n",
    "                else:\n",
    "                    level_list.append(volume[box[2]:min(volume.shape[0],box[5]+1), \n",
    "                                            box[1]:min(volume.shape[1],box[4]+1),\n",
    "                                            box[0]:min(volume.shape[2],box[3]+1)\n",
    "                                            ])\n",
    "            else:\n",
    "                level_list.append(None)\n",
    "\n",
    "\n",
    "        return level_ind_list, level_list\n",
    "    \n",
    "    def get_conditions_in_view(self, conditions_to_get, view, training=False):\n",
    "        cond_list = []\n",
    "        cond_ind_list = []\n",
    "        volume = self.get_in_view(view)\n",
    "        for l, level in self.levels.items():\n",
    "            if level is not None:\n",
    "                for condition in conditions_to_get:\n",
    "                    cond_ind_list.append((l, condition))\n",
    "                    cd = next((c for c in level.conditions if c.condition_name == condition), None)\n",
    "                    if cd is not None:\n",
    "                        box = np.array(cd.get_box_in_view_type(view))\n",
    "                        box = box.astype(int)\n",
    "                        if training:\n",
    "                            z0, z1 = max(0, box[2]+random.randint(-2,0)),min(volume.shape[0], box[5]+random.randint(0,2))\n",
    "                            h0, h1 = max(0, box[1]+random.randint(-5,5)),min(volume.shape[1], box[4]+random.randint(-5,5))\n",
    "                            w0, w1 = max(0, box[0]+random.randint(-5,5)),min(volume.shape[2], box[3]+random.randint(-5,5))\n",
    "                            cond_list.append(volume[z0: max(z1, z0+1), \n",
    "                                                    h0: max(h1, h0+1), \n",
    "                                                    w0: max(w1, w0+1)])\n",
    "                        else:\n",
    "                            cond_list.append(volume[box[2]:box[5]+1, box[1]:box[4]+1, box[0]:box[3]+1])\n",
    "                    else: \n",
    "                        cond_list.append(None)\n",
    "            else:\n",
    "                for condition in conditions_to_get:\n",
    "                    cond_ind_list.append((l, condition))\n",
    "                    cond_list.append(None)\n",
    "                \n",
    "\n",
    "        return cond_ind_list, cond_list\n",
    "    \n",
    "    def set_levels_from_boxes(self, boxes, box_view, boxed_im_size):\n",
    "        for box, level, score in zip(boxes['boxes'].detach().cpu().numpy(), boxes['labels'].detach().cpu().numpy(), boxes['scores'].detach().cpu().numpy()):\n",
    "            if box.argmax() > 1.:\n",
    "                box = box/np.array(boxed_im_size*2, dtype = float)[[2,1,0,5,4,3]]\n",
    "            box = Box3d.bbox_from_view(box, box_view).get_box_in_view_type('sagittal') * self.scale\n",
    "            box = Box3d.bbox_from_view(box, 'sagittal')\n",
    "            self.levels[self.level_names[level]] = Level(level, box, score)\n",
    "    \n",
    "    def plot_level_boxes(self, ax=None):\n",
    "        color_dict = dict([('L1/L2','r'),('L2/L3','darkorange'), ('L3/L4','gray'), ('L4/L5','m'), ('L5/S1', 'y')])\n",
    "        if ax is not None:\n",
    "            assert len(ax) == 2\n",
    "            ax=ax.flatten()\n",
    "        else: \n",
    "            fig, ax = plt.subplots(1, 2, figsize = (8, 8))\n",
    "        volume = self.volume\n",
    "        ax[0].imshow(volume[volume.shape[0]//2,:,:], aspect='auto')\n",
    "        ax[1].imshow(volume.transpose(2,1,0)[volume.shape[2]//2,:,:],aspect='auto')\n",
    "        \n",
    "        for level_name, level in self.levels.items():\n",
    "            if level is not None:\n",
    "                abox= np.array(level.get_box_in_view_type('sagittal'))\n",
    "                box = abox[[0,1,3,4]]\n",
    "                box2 = abox[[2,1,5,4]]\n",
    "                color = color_dict[level_name]\n",
    "                ax[0].add_patch(patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=1, edgecolor=color, facecolor='none'))\n",
    "                ax[0].text(box[2], box[1]+3, level_name, c=color)\n",
    "                ax[1].add_patch(patches.Rectangle((box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1], linewidth=1, edgecolor=color, facecolor='none'))\n",
    "                ax[1].text(box2[2], box2[1]+3, level_name, c=color)\n",
    "            # plot()\n",
    "        ax[0].set_title(self.series_type)\n",
    "        ax[0].axis('off')\n",
    "        ax[1].axis('off')\n",
    "        if ax is None:\n",
    "            plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "            plt.show()\n",
    "\n",
    "    def interactive_plot(self):\n",
    "        #add_points_to_plot - used to show how rest of the spine points (in different levels) will change during spine changing\n",
    "        params = {\n",
    "            'view': self.series_type,\n",
    "            }\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5,5))\n",
    "        ax.axis('off')\n",
    "        volume = self.get_in_view(self.series_type)\n",
    "        def plot_vid(i):\n",
    "            plt.cla()\n",
    "            ax.clear()\n",
    "            ax.imshow(volume[i].astype(np.uint8))\n",
    "            ax.axis('off')\n",
    "            for level in self.levels.values():\n",
    "                if level is not None:\n",
    "                    level_box = level.get_box_in_view_type(params['view'])\n",
    "                    if level_box[2] <= i and level_box[5] >= i: \n",
    "                        ax.annotate(level.level_name, (level_box[3]+5, level_box[1]), c=self.color_dict[level.level_name], fontsize = 'medium')\n",
    "                        ax.add_patch(patches.Rectangle((level_box[0],level_box[1]),level_box[3]-level_box[0], level_box[4]-level_box[1], linewidth=1, edgecolor=self.color_dict[level.level_name], fill=False))\n",
    "                        \n",
    "                        num = 0\n",
    "                        for condition in level.conditions:\n",
    "                            if condition.box is not None:\n",
    "                                num+=1\n",
    "                                condition_box = condition.get_box_in_view_type(params['view'])\n",
    "                                if condition_box[2] <= i and condition_box[5] >= i: \n",
    "                                    if \"Right\" in condition.condition_name and self.series_type != 'sagittal':\n",
    "                                        x, y = max(0,condition_box[0]-40), condition_box[1]\n",
    "                                    else:\n",
    "                                        x, y = max(0,condition_box[0]-40), condition_box[4]+10\n",
    "                                    an = condition.condition_name + \": \" +condition.status_name\n",
    "                                    ax.annotate(an, (x, y), c=self.color_dict[level.level_name], fontsize = 'small')\n",
    "\n",
    "                                    ax.add_patch(patches.Rectangle((condition_box[0],condition_box[1]),condition_box[3]-condition_box[0], condition_box[4]-condition_box[1], linewidth=1, \n",
    "                                                                edgecolor=self.color_dict[level.level_name], fill=False))\n",
    "                            else:\n",
    "                                ax.annotate(f\"{condition.condition_name}: {condition.status_name}\", (level_box[3]+5, level_box[1]+15), c=self.color_dict[level.level_name], fontsize = 'medium')\n",
    "                                \n",
    "        amn = animation.FuncAnimation(fig, lambda i : plot_vid(i), frames=range(0, volume.shape[0]))\n",
    "        # Demonstrate the animation\n",
    "        example = HTML(amn.to_jshtml())\n",
    "        plt.close()\n",
    "        return example, amn\n",
    "\n",
    "from glob import glob\n",
    "import dicomsdl as dicoml\n",
    "import os\n",
    "\n",
    "class Study(object):\n",
    "    def __init__(self,study_id, serieses:Dict[str, Series]):\n",
    "        self.serieses = serieses\n",
    "        self.study_id = study_id\n",
    "\n",
    "        self.condition_map= {\n",
    "            'Left Neural Foraminal Narrowing':0,\n",
    "            'Left Subarticular Stenosis':1,\n",
    "            'Right Neural Foraminal Narrowing':2,\n",
    "            'Right Subarticular Stenosis':3,\n",
    "            'Spinal Canal Stenosis':4}\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, series_type: str, view_type = None):\n",
    "        # series type - str [axial, sagittal, sagittal_t2]\n",
    "        # view_type - str [sagittal, coronal, axial]\n",
    "        if series_type in ['sagittal', 'sagittal_t1', 'sagittal_T1']:\n",
    "            return self.serieses['sagittal_t1']\n",
    "        elif series_type in ['sagittal_t2', 'sagittal_T2', 'SAGITTAL_T2']:\n",
    "            return self.serieses['sagittal_t2']\n",
    "        elif series_type in ['axial', 'axial_t2', 'axial_T2']:\n",
    "            return self.serieses['axial_t2']\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, path):\n",
    "        # check if folder has subfolders (in case of multiple serieses in study) like in RSNA Lumbar spine data\n",
    "        paths = glob(f'{path}/*/')\n",
    "        # if paths is empty threat it as folder with images\n",
    "        if not paths:\n",
    "            paths = [path] # if path leads to single series\n",
    "        \n",
    "        study = {\n",
    "            'sagittal_t1': [],\n",
    "            'sagittal_t2':[],\n",
    "            'axial_t2':[]\n",
    "        }\n",
    "        for series in paths:\n",
    "            files = os.listdir(series)\n",
    "            dataset = [(int(os.path.splitext(file)[0]), dicoml.open(f\"{series}/{file}\")) for file in files]\n",
    "            series_type = dataset[0][1].ImageOrientationPatient\n",
    "            series_desc = dataset[0][1].SeriesDescription\n",
    "            print(series_desc)\n",
    "            study_id = dataset[0][1].StudyID\n",
    "            widht = dataset[0][1].Columns\n",
    "            height = dataset[0][1].Rows\n",
    "            if np.array_equal(np.round(series_type), [0.,  1.,  0.,  0., 0., -1.]):\n",
    "                series_type = 'sagittal'\n",
    "                slices = sorted(dataset, key=lambda s: -s[1].ImagePositionPatient[0]) # sort left to right (if sagittal)\n",
    "                #print(slices)\n",
    "            elif np.array_equal(np.round(series_type), [1.,  0.,  0.,  0., 1., 0.]):\n",
    "                series_type = 'axial'\n",
    "                slices = sorted(dataset, key=lambda s: s[0]) # sort left to right (if sagittal)\n",
    "            else:\n",
    "                continue\n",
    "            # load images:\n",
    "            oimg = np.zeros((len(slices), height, widht), dtype = float)\n",
    "            for i, (instance, dimg) in enumerate(slices):  \n",
    "                img = dimg.pixelData()\n",
    "                if np.max(img) != 0:\n",
    "                    img = img / np.max(img)\n",
    "                img=(img * 255).astype(np.uint8)\n",
    "                try:      \n",
    "                    oimg[i,:,:] = img\n",
    "                except ValueError:\n",
    "                    oimg[i,:img.shape[0],:img.shape[1]] = img\n",
    "            if series_desc:\n",
    "                key = series_type+\"_\"+series_desc.lower()\n",
    "            else:\n",
    "                key = series_type+\"_\"+\"t2\" if series_type == 'axial' else series_type+\"_\"+\"t1\"\n",
    "            study[key].append(Series(oimg,series_type))\n",
    "        #print(study)\n",
    "        return cls(study_id, study)\n",
    "\n",
    "    @classmethod\n",
    "    def from_tensor_dict(cls, tensor_dict):\n",
    "        # load serieses from dictionary of tensors (for tests)\n",
    "        study = {\n",
    "            'sagittal_t1': [],\n",
    "            'sagittal_t2':[],\n",
    "            'axial_t2':[]\n",
    "        }\n",
    "        for key, val in tensor_dict.items():\n",
    "            if key == 'sagittal':\n",
    "                key = 'sagittal_t1'\n",
    "            if key == 'sagittal_t2':\n",
    "                key = 'sagittal_t2'\n",
    "            if key == 'axial':\n",
    "                key = 'axial_t2'\n",
    "\n",
    "            if key == 'study_id':\n",
    "                study_id = val\n",
    "                continue\n",
    "            if len(val) < 1:\n",
    "                    continue\n",
    "            for series in val:\n",
    "                if series.count_nonzero() < 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    study[key].append(Series(series.clone().detach().cpu().squeeze().numpy(), key.split('_')[0]))\n",
    "        return cls(study_id, study)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.serieses) \n",
    "    def items(self):\n",
    "        return self.serieses.items()\n",
    "    def keys(self):\n",
    "        return self.serieses.keys()\n",
    "    def values(self):\n",
    "        return self.serieses.values()\n",
    "    \n",
    "\n",
    "    def get_levels_in_view(self, series_type, view, training=False):\n",
    "        level_list = []\n",
    "        level_ind_list = []\n",
    "\n",
    "        for series in self[series_type]:\n",
    "            lil, ll = series.get_levels_in_view(view, training=training)\n",
    "            if not level_list and not level_ind_list:\n",
    "                level_ind_list = lil\n",
    "                level_list = ll\n",
    "            else:\n",
    "                for i, (level_o, level_c) in enumerate(zip(level_list, ll)):\n",
    "                    if level_o is None and level_c is not None: \n",
    "                        level_list[i] = level_c\n",
    "        return level_ind_list, level_list\n",
    "\n",
    "    def get_conditions_in_view(self, series_type, conditions_to_get, view, training=False):\n",
    "        cond_list = []\n",
    "        cond_ind_list = []\n",
    "        \n",
    "        for series in self[series_type]:\n",
    "            cil, cl = series.get_conditions_in_view(conditions_to_get, view, training=training)\n",
    "            if not cond_ind_list and not cond_list:\n",
    "                cond_ind_list = cil\n",
    "                cond_list = cl\n",
    "            else:\n",
    "                for i, (cond_n, cond_o) in enumerate(zip(cl, cond_list)):\n",
    "                    if cond_o is None and cond_n is not None: \n",
    "                        cond_ind_list[i] = cond_n\n",
    "        return cond_ind_list, cond_list\n",
    "    \n",
    "    def plot_levels(self):\n",
    "        ax_num = sum([len(series) for _, series in self.items()])\n",
    "        fig, ax = plt.subplots(2, ax_num, figsize = (12, 8))\n",
    "        i = 0\n",
    "        for serieses in self.values():\n",
    "            for series in serieses:\n",
    "                if series is not None:\n",
    "                    series.plot_level_boxes(ax[:,i])\n",
    "                    i+=1\n",
    "         \n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "        plt.show()\n",
    "\n",
    "    def get_condition_as_tensor(self):\n",
    "        results = torch.ones((5, 5, 3))/3\n",
    "        for serieses in self.values():\n",
    "            for series in serieses:\n",
    "                if series is not None:\n",
    "                    for i, (key, level) in enumerate(series.levels.items()):\n",
    "                        if level is not None:\n",
    "                            for condition in level.conditions:\n",
    "                                if condition.status is not None:\n",
    "                                    results[i, self.condition_map[condition.condition_name], :] = torch.tensor(condition.status, dtype = results.dtype)\n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Study.from_folder(\"/workspaces/RSNA_LSDC/inputs/rsna-2024-lumbar-spine-degenerative-classification/train_images/13317052\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDetectEstimate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda'\n",
    "\n",
    "         #################################DETECTORS#############################################\n",
    "        self.level_detector_model_config = {\n",
    "            'backbone_name': 'resnet_18', \n",
    "            'series_dim': [96]*3,\n",
    "            'device': 'cuda',\n",
    "            'use_features': [0,1],\n",
    "            'reg_max': 12, \n",
    "            'pretrained': False, \n",
    "            'num_classes':5,\n",
    "            'postprocess': Nms3d(0.3, 0.3, True)\n",
    "        }\n",
    "\n",
    "        # level detector\n",
    "        #model\n",
    "        self.level_detector = BoxModel(**self.level_detector_model_config).to(self.device).eval()\n",
    "        self.level_detector.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/level_detector_mednet18_96x3_best.pt'))\n",
    "        # rescaler\n",
    "        self.resize_for_ld= torch.nn.Upsample(size=self.level_detector_model_config['series_dim'], mode='trilinear').to(self.device)\n",
    "\n",
    "        #f sub/foraminal axial detector\n",
    "        self.sub_detector_model_config = {\n",
    "            'backbone_name': 'resnet_18', \n",
    "            'series_dim': [48, 96, 96],\n",
    "            'device': 'cuda',\n",
    "            'use_features': [0,1],\n",
    "            'reg_max': 16, \n",
    "            'pretrained': False, \n",
    "            'num_classes':1,\n",
    "            'postprocess': Nms3dAxial(0.1, 0.05, False, 1)\n",
    "        }\n",
    "\n",
    "        self.axial_detector = BoxModel(**self.sub_detector_model_config).to(self.device).eval()\n",
    "        self.axial_detector.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/sub_detect_axial_mednet18_96_96_48_best.pt'))\n",
    "        self.resize_for_sub= torch.nn.Upsample(size=self.sub_detector_model_config['series_dim'], mode='trilinear')\n",
    "\n",
    "        #f foraminal detector\n",
    "        self.foramina_detector_model_config = {\n",
    "            'backbone_name': 'resnet_18', \n",
    "            'series_dim': [48, 96, 96],\n",
    "            'device': 'cuda',\n",
    "            'use_features': [0,1],\n",
    "            'reg_max': 16, \n",
    "            'pretrained': False, \n",
    "            'num_classes':1,\n",
    "            'postprocess': Nms3dSagittalForamina(0.1, 0.05, True, 1)\n",
    "        }\n",
    "\n",
    "        self.sagittal_detector = BoxModel(**self.foramina_detector_model_config).to(self.device).eval()\n",
    "        self.sagittal_detector.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/foramina_detect_sagittal_mednet18_96_96_48_best.pt'))\n",
    "        self.resize_for_sagittal= torch.nn.Upsample(size=self.foramina_detector_model_config['series_dim'], mode='trilinear')\n",
    "\n",
    "        #################################ESTIMATORS#############################################\n",
    "        # canale estimator\n",
    "        self.canale_estimator_model_config = {\n",
    "            'backbone_name': 'densenet121', \n",
    "            'series_dim': [10, 80, 80],\n",
    "            'pretrained': False, \n",
    "            }\n",
    "        \n",
    "        self.canale_esitmator = ClassModelTimm2d(**self.canale_estimator_model_config).to(self.device).eval()\n",
    "        self.canale_esitmator.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/densenset121_80_80_10_canale_best.pt'))\n",
    "        self.resize_for_canale = torch.nn.Upsample(size=self.canale_estimator_model_config['series_dim'], mode='trilinear').to(self.device)\n",
    "\n",
    "        # sub estimator\n",
    "        self.sub_estimator_model_config = {\n",
    "            'backbone_name': 'densenet121', \n",
    "            'series_dim': [8, 80, 80],\n",
    "            'pretrained': False, \n",
    "            }\n",
    "        \n",
    "        self.sub_estimator = ClassModelTimm2d(**self.sub_estimator_model_config).to(self.device).eval()\n",
    "        self.sub_estimator.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/densenet121_80_80_8_subs_best.pt'))\n",
    "        self.resize_for_sub_estimator = torch.nn.Upsample(size=self.sub_estimator_model_config['series_dim'], mode='trilinear').to(self.device)\n",
    "\n",
    "        # foramina estimator\n",
    "        self.foramina_estimator_model_config = {\n",
    "            'backbone_name': 'densenet121', \n",
    "            'series_dim': [3, 80, 80],\n",
    "            'pretrained': False, \n",
    "            }\n",
    "        \n",
    "        self.foramina_estimator = ClassModelTimm2d(**self.foramina_estimator_model_config).to(self.device).eval()\n",
    "        self.foramina_estimator.load_state_dict(torch.load('/workspaces/RSNA_LSDC/model_weight/densenet121_80_80_3_foramina_best.pt'))\n",
    "        self.resize_for_foramina_estimator = torch.nn.Upsample(size=self.foramina_estimator_model_config['series_dim'], mode='trilinear').to(self.device)\n",
    "\n",
    "        self.train_transforms = v2.Compose([\n",
    "            v2.RandomChoice([v2.RandomVerticalFlip(p = 0.5), v2.RandomHorizontalFlip(p = 0.5), v2.RandomAffine(degrees=5), \n",
    "                            v2.RandomRotation(degrees=(90,90)), v2.RandomRotation(degrees=(-90,-90))]),\n",
    "            v2.RandomChoice([v2.RandomAffine(degrees=0, scale=(0.8,1.2)), v2.RandomPerspective(distortion_scale=0.2, p=1.0), v2.RandomAffine(degrees=0, translate=(0.3,0.3), shear=(-5,5,-5,5))]), # translation + shearing\n",
    "            v2.RandomChoice([v2.GaussianBlur(kernel_size=(3,7), sigma=(0.1, 0.7))]),\n",
    "        ])\n",
    "        \n",
    "    def normalize_volume(self, volume, type=0):\n",
    "        if type==0:\n",
    "            return (volume - 0.5*255.)/(0.5 *255.)\n",
    "        else:\n",
    "            pixels = volume[volume > 0]\n",
    "            if pixels.size==0:\n",
    "                return volume\n",
    "            \n",
    "            mean = pixels.mean()\n",
    "            std  = pixels.std()\n",
    "            out = (volume - mean)/std\n",
    "            #out_random = np.random.normal(0, 1, size = volume.shape)\n",
    "            #out[volume == 0] = out_random[volume == 0]\n",
    "        return out\n",
    "\n",
    "\n",
    "    def limit_series(self, img, series_length):\n",
    "        if series_length < img.shape[0]:\n",
    "            st = np.round(np.linspace(0, img.shape[0] - 1, series_length)).astype(int)\n",
    "            img = img[st,:,:]\n",
    "        elif series_length > img.shape[0]:\n",
    "            img = F.pad(img, (0, 0, 0, 0, 0, series_length-img.shape[0]))\n",
    "        return img\n",
    "    \n",
    "\n",
    "    def resize_data(self, volume, resizer, series_dim=None, dim_reduction='scale'):\n",
    "        #scale - use trilinear interpolation to include scaling linearly in volume depth dimention\n",
    "        #limit - limit series length by selecting equalu spaced lices/padding end with zeros\n",
    "        if dim_reduction=='limit':\n",
    "            assert series_dim is not None\n",
    "            volume = self.limit_series(volume, series_dim[0])\n",
    "        return resizer(volume.reshape(1, 1, *volume.shape)).squeeze(1).to(self.device)\n",
    "    \n",
    "    \n",
    "    def predict(self, series):\n",
    "        # series - dict consisting of segittal, sagittal t2 and axial volumes with original dimentions \n",
    "        #print(series['study_id'])\n",
    "        if isinstance(series, str):\n",
    "            study = Study.from_folder(series)\n",
    "        else:\n",
    "            study = Study.from_tensor_dict(series)\n",
    "        \n",
    "        for series_type, serieses in study.items():\n",
    "            for series in serieses:\n",
    "                if series is not None:\n",
    "                    level_boxes = self.get_levels(torch.tensor(series.get_in_view('sagittal'), dtype=torch.float).to(self.device))[0]\n",
    "                    series.set_levels_from_boxes(level_boxes, 'sagittal', self.level_detector_model_config['series_dim'])\n",
    "\n",
    "        # detect subarticular regions from axial scan\n",
    "        if len(study['axial'])>0:\n",
    "            for series in study['axial']:\n",
    "                axial_lvl_ind, axial_lvls = series.get_levels_in_view('axial')\n",
    "                axial_for_sub = self.detect_fs_axial(axial_lvls)\n",
    "                for ali, afs in zip(axial_lvl_ind, axial_for_sub):\n",
    "                    if series.levels[ali] is not None:\n",
    "                        series.levels[ali].add_conditions_from_boxes(afs, dict([(0, 'Subarticular Stenosis')]), #(1, 'Subarticular Stenosis')\n",
    "                                                                            self.sub_detector_model_config['series_dim'], 'axial')\n",
    "                    \n",
    "         # detect foramina regions from sagittal scan\n",
    "        if len(study['sagittal'])>0:\n",
    "            for series in study['sagittal']:\n",
    "                sagittal_lvl_ind, sagittal_lvls = series.get_levels_in_view('sagittal')\n",
    "                sagittal_for_foramina = self.detect_foramina_sagittal(sagittal_lvls)\n",
    "                for sli, sfs in zip(sagittal_lvl_ind, sagittal_for_foramina):\n",
    "                    if series.levels[sli] is not None:\n",
    "                        series.levels[sli].add_conditions_from_boxes(sfs, dict([(0, 'Neural Foraminal Narrowing')]),\n",
    "                                                                            self.foramina_detector_model_config['series_dim'], 'sagittal')\n",
    "\n",
    "\n",
    "        # using sagittal t2 levels predict canale condition\n",
    "        if len(study['sagittal_t2'])>0:\n",
    "            for series in study['sagittal_t2']:\n",
    "                sagittal_lvl_ind, sagittal_lvls = series.get_levels_in_view('sagittal')\n",
    "                level_canale_condition = self.estimate_canales(sagittal_lvls).squeeze(0)\n",
    "                for sli, lcc in zip(sagittal_lvl_ind, level_canale_condition.detach().cpu().numpy()):\n",
    "                    if series.levels[sli] is not None:\n",
    "                        series.levels[sli].add_condition('Spinal Canal Stenosis', status=lcc)\n",
    "\n",
    "        # estimate subarticular stenosis condition from axial scan\n",
    "        if len(study['axial'])>0:\n",
    "            for series in study['axial']:\n",
    "                axial_cond_ind, axial_cond = series.get_conditions_in_view(['Left Subarticular Stenosis', 'Right Subarticular Stenosis'], 'axial')\n",
    "                axial_sub_conditions = self.estimate_subarticular(axial_cond).squeeze(0)\n",
    "                for aci, asc in zip(axial_cond_ind, axial_sub_conditions.detach().cpu().numpy()):\n",
    "                    if series.levels[aci[0]] is not None:\n",
    "                        series.levels[aci[0]].set_status_to_condition(aci[1], asc)\n",
    "\n",
    "        # estimate foraminal narrowing from sagittal scan\n",
    "        if len(study['sagittal'])>0:\n",
    "            for series in study['sagittal']:\n",
    "                sagittal_cond_ind, sagittal_cond = series.get_conditions_in_view(['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'], 'sagittal')\n",
    "                sagittal_fora_sonditions = self.estimate_foraminal(sagittal_cond).squeeze(0)\n",
    "                for sfi, sfc in zip(sagittal_cond_ind, sagittal_fora_sonditions.detach().cpu().numpy()):\n",
    "                    if series.levels[sfi[0]] is not None:\n",
    "                        series.levels[sfi[0]].set_status_to_condition(sfi[1], sfc)\n",
    "\n",
    "        return study \n",
    "    \n",
    "    def get_loss(self, series, labels_canale, labels_subarticulars, labels_foramina, masks_canale, mask_subarticulars, mask_foramina):\n",
    "        # series - dict consisting of segittal, sagittal t2 and axial volumes with original dimentions \n",
    "        study = Study.from_tensor_dict(series)\n",
    "        for series_type, serieses in study.items():\n",
    "            for series in serieses:\n",
    "                if series is not None:\n",
    "                    level_boxes = self.get_levels(torch.tensor(series.get_in_view('sagittal'), dtype=torch.float).to(self.device))[0]\n",
    "                    series.set_levels_from_boxes(level_boxes, 'sagittal', self.level_detector_model_config['series_dim'])\n",
    "\n",
    "\n",
    "        # using sagittal t2 levels predict canale condition\n",
    "        loss_canale = torch.tensor(0., dtype = torch.float)\n",
    "        metrics_canale = {}\n",
    "        if len(study['sagittal_t2'])>0:\n",
    "            _, sagittal_lvls = study.get_levels_in_view('sagittal_t2', 'sagittal', True)\n",
    "            loss_canale, metrics_canale = self.estimate_canales(sagittal_lvls, labels_canale, masks_canale)\n",
    "\n",
    "        # detect subarticular regions from axial scan\n",
    "        if len(study['axial']) > 0:\n",
    "            for series in study['axial']:\n",
    "                axial_lvl_ind, axial_lvls = series.get_levels_in_view('axial')\n",
    "                axial_for_sub = self.detect_fs_axial(axial_lvls)\n",
    "                for ali, afs in zip(axial_lvl_ind, axial_for_sub):\n",
    "                    if series.levels[ali] is not None:\n",
    "                        series.levels[ali].add_conditions_from_boxes(afs, dict([(0, 'Subarticular Stenosis')]), #(1, 'Subarticular Stenosis')\n",
    "                                                                            self.sub_detector_model_config['series_dim'], 'axial')\n",
    "                    \n",
    "         # detect foramina regions from sagittal scan\n",
    "        if len(study['sagittal']) > 0:\n",
    "            for series in study['sagittal']:\n",
    "                sagittal_lvl_ind, sagittal_lvls = series.get_levels_in_view('sagittal')\n",
    "                sagittal_for_foramina = self.detect_foramina_sagittal(sagittal_lvls)\n",
    "                for sli, sfs in zip(sagittal_lvl_ind, sagittal_for_foramina):\n",
    "                    if series.levels[sli] is not None:\n",
    "                        series.levels[sli].add_conditions_from_boxes(sfs, dict([(0, 'Neural Foraminal Narrowing')]),\n",
    "                                                                            self.foramina_detector_model_config['series_dim'], 'sagittal')\n",
    "\n",
    "        # estimate subarticular stenosis condition from axial scan\n",
    "        loss_sub = torch.tensor(0., dtype = torch.float)\n",
    "        metrics_sub = {}\n",
    "        if len(study['axial']) > 0:\n",
    "            _, axial_cond = study.get_conditions_in_view('axial', ['Left Subarticular Stenosis', 'Right Subarticular Stenosis'], 'axial', True)\n",
    "            loss_sub, metrics_sub = self.estimate_subarticular(axial_cond, labels_subarticulars, mask_subarticulars)\n",
    "\n",
    "        # estimate subarticular stenosis condition from axial scan\n",
    "        loss_foramina = torch.tensor(0., dtype = torch.float)\n",
    "        metrics_foramina = {}\n",
    "        if len(study['sagittal']) > 0:\n",
    "            _, sagittal_cond = study.get_conditions_in_view('sagittal', ['Left Neural Foraminal Narrowing', 'Right Neural Foraminal Narrowing'], 'sagittal', True)\n",
    "            loss_foramina, metrics_foramina = self.estimate_foraminal(sagittal_cond, labels_foramina, mask_foramina)\n",
    "\n",
    "        return loss_canale+loss_sub +loss_foramina, metrics_canale, metrics_sub, metrics_foramina #level_canale_condition\n",
    "\n",
    "    def get_levels(self, series:torch.tensor, prepared:bool=False) -> List[Dict]:\n",
    "        # series torch tensor in shape [d, h, w]\n",
    "        if not prepared:\n",
    "            series = self.normalize_volume(self.resize_data(series.to(self.device), self.resize_for_ld))\n",
    "        return self.level_detector.predict(series)\n",
    "        \n",
    "    def detect_fs_axial(self, levels):\n",
    "        prepared_levels=[]\n",
    "        for level in levels:\n",
    "            if level is not None:\n",
    "                level = torch.tensor(level, dtype=torch.float).to(self.device)\n",
    "                prepared_levels.append(self.normalize_volume(self.resize_data(level, self.resize_for_sub, dim_reduction='scale'), type=1))\n",
    "            else:\n",
    "                prepared_levels.append(torch.zeros((1,*self.sub_detector_model_config['series_dim'])).to(self.device))    \n",
    "\n",
    "        return self.axial_detector.predict((torch.cat(prepared_levels, dim=0)))\n",
    "    \n",
    "    def detect_foramina_sagittal(self, levels):\n",
    "        prepared_levels=[]\n",
    "        for level in levels:\n",
    "            if level is not None:\n",
    "                level = torch.tensor(level, dtype=torch.float).to(self.device)\n",
    "                prepared_levels.append(self.normalize_volume(self.resize_data(level, self.resize_for_sagittal, dim_reduction='scale'), type=1))\n",
    "            else:\n",
    "                prepared_levels.append(torch.zeros((1,*self.foramina_detector_model_config['series_dim'])).to(self.device))    \n",
    "\n",
    "        return self.sagittal_detector.predict((torch.cat(prepared_levels, dim=0)))\n",
    "\n",
    "    def estimate_canales(self, series, *args) -> torch.tensor:\n",
    "        # level torch list of tensors in shape [d, h, w]\n",
    "        # return list of results\n",
    "    \n",
    "        prepared_levels = []\n",
    "        for level in series:\n",
    "            if level is not None:\n",
    "\n",
    "                level = torch.tensor(level, dtype=torch.float).to(self.device)\n",
    "                prepared_levels.append(self.normalize_volume(self.resize_data(level, self.resize_for_canale, dim_reduction='scale'), type=1).unsqueeze(1))\n",
    "            else:\n",
    "                prepared_levels.append(torch.zeros((1,1,*self.canale_estimator_model_config['series_dim'])).to(self.device))\n",
    "\n",
    "        if self.canale_esitmator.training:\n",
    "            volume = self.train_transforms(torch.cat(prepared_levels, dim=0))\n",
    "            return self.canale_esitmator.get_loss(volume, *args)\n",
    "        else:\n",
    "            return self.canale_esitmator.predict(torch.cat(prepared_levels, dim=0))\n",
    "        \n",
    "    def estimate_subarticular(self, series, *args) -> torch.tensor:\n",
    "        # level torch list of tensors in shape [d, h, w]\n",
    "        # return list of results\n",
    "    \n",
    "        prepared_levels = []\n",
    "        for level in series:\n",
    "            if level is not None:\n",
    "                level = torch.tensor(level, dtype=torch.float).to(self.device)\n",
    "                prepared_levels.append(self.normalize_volume(self.resize_data(level, self.resize_for_sub_estimator, dim_reduction='scale'), type=1).unsqueeze(1))\n",
    "            else:\n",
    "                prepared_levels.append(torch.zeros((1,1,*self.sub_estimator_model_config['series_dim'])).to(self.device))\n",
    "\n",
    "        if self.sub_estimator.training:\n",
    "            volume = self.train_transforms(torch.cat(prepared_levels, dim=0))\n",
    "            return self.sub_estimator.get_loss(volume, *args)\n",
    "        else:\n",
    "            return self.sub_estimator.predict(torch.cat(prepared_levels, dim=0))\n",
    "        \n",
    "    def estimate_foraminal(self, series, *args) -> torch.tensor:\n",
    "        # level torch list of tensors in shape [d, h, w]\n",
    "        # return list of results\n",
    "\n",
    "        prepared_levels = []\n",
    "        for level in series:\n",
    "            if level is not None:\n",
    "                level = torch.tensor(level, dtype=torch.float).to(self.device)\n",
    "                prepared_levels.append(self.normalize_volume(self.resize_data(level, self.resize_for_foramina_estimator, dim_reduction='scale'), type=1).unsqueeze(1))\n",
    "            else:\n",
    "                prepared_levels.append(torch.zeros((1,1,*self.foramina_estimator_model_config['series_dim'])).to(self.device))\n",
    "\n",
    "        if self.foramina_estimator.training:\n",
    "            volume = self.train_transforms(torch.cat(prepared_levels, dim=0))\n",
    "            return self.foramina_estimator.get_loss(volume, *args)\n",
    "        else:\n",
    "            return self.foramina_estimator.predict(torch.cat(prepared_levels, dim=0))\n",
    "        \n",
    "    def train(self):\n",
    "        self.canale_esitmator.train()\n",
    "        self.sub_estimator.train()\n",
    "        self.foramina_estimator.train()\n",
    "    \n",
    "    def eval(self):\n",
    "        self.canale_esitmator.eval()\n",
    "        self.sub_estimator.eval()\n",
    "        self.foramina_estimator.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelDetectEstimate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "study = model.predict(\"/workspaces/RSNA_LSDC/inputs/rsna-2024-lumbar-spine-degenerative-classification/train_images/117720278\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.plot_levels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ani = study['sagittal'][0].interactive_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ani.save('subarticular_detection_example.gif', writer='Pillow', fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_config ={\n",
    "    'dataset_path': \"/workspaces/RSNA_LSDC/inputs/dataset_vl\",\n",
    "    'load_series': ['sagittal', 'sagittal_t2', 'axial'], # series types to load into dataset ['sagittal', 'axial', 'sagittal_t2']\n",
    "    \n",
    "    'return_series_type': False, # If True getitem will also return series orignial type\n",
    "    'image_type': 'png',\n",
    "}\n",
    "\n",
    "val_dataset_config = copy.deepcopy(train_dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    \"print_evaluation\": True,\n",
    "    \"steps_per_plot\": 1,\n",
    "\n",
    "    \"checkpoints\": False,\n",
    "    \"save_path\": \"/workspaces/RSNA_LSDC/models_3d_final/model_weight\",\n",
    "    \"step_per_save\":100,\n",
    "    \"model_name\": \"efficientnet_b2_80_80_10_finetuned\",\n",
    "    \"train_dataset_config\": train_dataset_config,\n",
    "    \"val_dataset_config\": val_dataset_config,\n",
    "\n",
    "    \"epochs\": 10, \n",
    "    \"batch_size\": 1,\n",
    "\n",
    "    \"optimizer\": torch.optim.AdamW, #torch.optim.AdamW,#torch.optim.Adam,\n",
    "    \"optimizer_params\": {'lr':3e-5}, #,'weight_decay': 1e-3 },#, 'weight_decay': 1e-3, 'momentum': 0.98},#, 'momentum': 0.98, 'weight_decay': 1e-3},#, 'momentum':0.98, 'weight_decay':1e-5},#, 'momentum':0.9},\n",
    "    \"scheduler\": torch.optim.lr_scheduler.CosineAnnealingWarmRestarts, #torch.optim.lr_scheduler.CosineAnnealingWarmRestarts, #torch.optim.lr_scheduler.ExponentialLR, #torch.optim.lr_scheduler.OneCycleLR\n",
    "    \"scheduler_params\": {'T_0': 10, 'T_mult': 2, 'eta_min':3e-9}, #{'T_0': 2, 'T_mult': 2, 'eta_min':3e-5}, #{'max_lr': 0.001, 'epochs': None, 'steps_per_epoch':None}, {'gamma':0.9}\n",
    "\n",
    "    \"early_stopping\": False,\n",
    "    \"early_stopping_treshold\": 0.1,\n",
    "    'vsa':False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd = pd.read_csv(f'/workspaces/RSNA_LSDC/inputs/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv').iloc[0:300]\n",
    "def kfoldCV(k, trainer_config):\n",
    "    model_summaries = []\n",
    "    data_sagittal = pd.read_pickle(\"/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_unified_sagital_t1.pkl\")\n",
    "    data_sagittal_t2 = pd.read_pickle(\"/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_unified_sagital_t2.pkl\")\n",
    "    data_axial = pd.read_pickle('/workspaces/RSNA_LSDC/inputs/box_data/coordinates/coordinates_axial_unified.pkl')\n",
    "    unique_studies = np.random.permutation(np.array(tsd.study_id.unique()))\n",
    "    if k == 1:\n",
    "        with open('/workspaces/RSNA_LSDC/inputs/train_unique_studies.npy', 'rb') as f:\n",
    "            train = np.load(f)\n",
    "        with open('/workspaces/RSNA_LSDC/inputs/test_unique_studies.npy', 'rb') as f:\n",
    "            test = np.load(f) \n",
    "        folds = [test, train[:1]]\n",
    "    else:\n",
    "        folds = np.array_split(unique_studies, k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(f\"Fold: {i}\")\n",
    "        train_ids = np.concatenate(folds[:i]+folds[i+1:], axis=0)\n",
    "        train_data={'sagittal': data_sagittal[data_sagittal.study_id.isin(train_ids)],\n",
    "                    'sagittal_t2': data_sagittal_t2[data_sagittal_t2.study_id.isin(train_ids)],\n",
    "                    'axial': data_axial[data_axial.study_id.isin(train_ids)]}\n",
    "        val_data=  {'sagittal': data_sagittal[data_sagittal.study_id.isin(folds[i])],\n",
    "                    'sagittal_t2': data_sagittal_t2[data_sagittal_t2.study_id.isin(folds[i])],\n",
    "                    'axial': data_axial[data_axial.study_id.isin(folds[i])]}\n",
    "        \n",
    "        trainer = SagittalTrainer(ModelDetectEstimate, trainer_config, train_data, val_data)\n",
    "        trainer.train()\n",
    "        model_summaries.append(trainer.get_summary())\n",
    "\n",
    "    return model_summaries\n",
    "# convformer_s18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfoldCV(1, trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
